{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a88c1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/hb/p4pxwc3932xc9mknn5vhl8br0000gr/T/ipykernel_2316/4205298130.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m df.columns = df.columns.str.strip().str.lower()\n\u001b[32m      9\u001b[39m df = df.dropna(subset=[\u001b[33m\"wavelength\"\u001b[39m])  \u001b[38;5;66;03m# remove empty wavelength rows\u001b[39;00m\n\u001b[32m     10\u001b[39m df[\u001b[33m\"wavelength\"\u001b[39m] = pd.to_numeric(df[\u001b[33m\"wavelength\"\u001b[39m], errors=\u001b[33m\"coerce\"\u001b[39m)\n\u001b[32m     11\u001b[39m df = df.dropna(subset=[\u001b[33m\"wavelength\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = df.sort_values([\u001b[33m\"filename\"\u001b[39m, \u001b[33m\"wavelength\"\u001b[39m])\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# --- Identify parameters present ---\u001b[39;00m\n\u001b[32m     15\u001b[39m params = [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;28;01min\u001b[39;00m [\u001b[33m\"agp\"\u001b[39m, \u001b[33m\"cgp\"\u001b[39m, \u001b[33m\"ap\"\u001b[39m, \u001b[33m\"ag\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;28;01min\u001b[39;00m df.columns]\n",
      "\u001b[32m/opt/anaconda3/envs/NewEnvironment/lib/python3.13/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7175\u001b[39m                 f\"Length of ascending ({len(ascending)})\"  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7176\u001b[39m                 f\" != length of by ({len(by)})\"\n\u001b[32m   7177\u001b[39m             )\n\u001b[32m   7178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7179\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7180\u001b[39m \n\u001b[32m   7181\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7182\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m/opt/anaconda3/envs/NewEnvironment/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'filename'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ”¹ Load your combined ACS file\n",
    "file_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- Clean up ---\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.dropna(subset=[\"wavelength\"])  # remove empty wavelength rows\n",
    "df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"wavelength\"])\n",
    "df = df.sort_values([\"filename\", \"wavelength\"])\n",
    "\n",
    "# --- Identify parameters present ---\n",
    "params = [p for p in [\"agp\", \"cgp\", \"ap\", \"ag\"] if p in df.columns]\n",
    "\n",
    "# --- Build transposed (pivoted) tables for each parameter ---\n",
    "pivoted_dfs = []\n",
    "for param in params:\n",
    "    pivot = df.pivot_table(index=[\"filename\"], columns=\"wavelength\", values=param)\n",
    "    pivot.columns = [f\"{param}_{int(c)}\" for c in pivot.columns]\n",
    "    pivoted_dfs.append(pivot)\n",
    "\n",
    "# --- Merge all parameter tables horizontally ---\n",
    "combined = pd.concat(pivoted_dfs, axis=1).reset_index()\n",
    "\n",
    "# --- (Optional) add cruise if present ---\n",
    "if \"cruise\" in df.columns:\n",
    "    cruise_map = df.drop_duplicates(subset=[\"filename\"])[[\"filename\", \"cruise\"]]\n",
    "    combined = combined.merge(cruise_map, on=\"filename\", how=\"left\")\n",
    "\n",
    "# --- Reorder columns ---\n",
    "cols = [\"cruise\", \"filename\"] + [c for c in combined.columns if c not in [\"cruise\", \"filename\"]]\n",
    "combined = combined[cols]\n",
    "\n",
    "# --- Save the final transposed DataFrame ---\n",
    "output_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_transposed.csv\"\n",
    "combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Transposed file saved to:\\n{output_path}\")\n",
    "print(f\"Columns created: {len(combined.columns)} | Rows: {len(combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3698223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transposed file saved successfully at:\n",
      "/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_transposed.csv\n",
      "Columns created: 1206 | Rows: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ”¹ Load your combined ACS file\n",
    "file_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- Clean column names ---\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# --- Ensure wavelength is numeric ---\n",
    "if \"wavelength\" not in df.columns:\n",
    "    raise ValueError(\"âŒ 'wavelength' column not found in file â€” check your CSV headers.\")\n",
    "\n",
    "df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"wavelength\"])\n",
    "\n",
    "# --- If 'filename' not in columns, create a placeholder ---\n",
    "if \"filename\" not in df.columns:\n",
    "    df[\"filename\"] = \"unknown_file\"\n",
    "\n",
    "# --- If 'cruise' not in columns, add it too (optional) ---\n",
    "if \"cruise\" not in df.columns:\n",
    "    df[\"cruise\"] = \"unknown_cruise\"\n",
    "\n",
    "# --- Sort safely ---\n",
    "df = df.sort_values([\"filename\", \"wavelength\"])\n",
    "\n",
    "# --- Identify optical parameters present ---\n",
    "params = [p for p in [\"agp\", \"cgp\", \"ap\", \"ag\"] if p in df.columns]\n",
    "\n",
    "# --- Build transposed (pivoted) tables for each parameter ---\n",
    "pivoted_dfs = []\n",
    "for param in params:\n",
    "    pivot = df.pivot_table(index=[\"filename\"], columns=\"wavelength\", values=param)\n",
    "    pivot.columns = [f\"{param}_{int(c)}\" for c in pivot.columns]\n",
    "    pivoted_dfs.append(pivot)\n",
    "\n",
    "# --- Merge all parameter tables ---\n",
    "combined = pd.concat(pivoted_dfs, axis=1).reset_index()\n",
    "\n",
    "# --- Add cruise info back in ---\n",
    "cruise_map = df.drop_duplicates(subset=[\"filename\"])[[\"filename\", \"cruise\"]]\n",
    "combined = combined.merge(cruise_map, on=\"filename\", how=\"left\")\n",
    "\n",
    "# --- Reorder columns ---\n",
    "cols = [\"cruise\", \"filename\"] + [c for c in combined.columns if c not in [\"cruise\", \"filename\"]]\n",
    "combined = combined[cols]\n",
    "\n",
    "# --- Save the transposed DataFrame ---\n",
    "output_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_transposed.csv\"\n",
    "combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Transposed file saved successfully at:\\n{output_path}\")\n",
    "print(f\"Columns created: {len(combined.columns)} | Rows: {len(combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a1ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transposed wavelengths saved to:\n",
      "/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_transposed.csv\n",
      "Shape: (4, 11739)\n",
      "wavelength       400       401       402       403       404       405  \\\n",
      "agp         0.077334  0.077756  0.078085  0.077690  0.078085  0.078085   \n",
      "cgp         0.219700  0.218710  0.217730  0.216390  0.215540  0.214750   \n",
      "ap          0.008705  0.009381  0.010058  0.011752  0.012013  0.012232   \n",
      "ag          0.069318  0.068140  0.066961  0.066425  0.065853  0.065677   \n",
      "\n",
      "wavelength       406       407       408       409  ...       691       692  \\\n",
      "agp         0.077690  0.077300  0.075613  0.074218  ...  0.010166  0.009759   \n",
      "cgp         0.214200  0.214160  0.213750  0.213680  ...  0.133130  0.132740   \n",
      "ap          0.014352  0.014638  0.014827  0.014827  ...  0.009278  0.008959   \n",
      "ag          0.064252  0.061944  0.060974  0.058606  ...  0.000887  0.000800   \n",
      "\n",
      "wavelength       693       694       695       696       697       698  \\\n",
      "agp         0.009488  0.009174  0.008859  0.008533  0.008230  0.007899   \n",
      "cgp         0.132450  0.132160  0.131810  0.131640  0.131460  0.131230   \n",
      "ap          0.008758  0.008502  0.008320  0.008116  0.007903  0.007741   \n",
      "ag          0.000730  0.000672  0.000539  0.000417  0.000327  0.000158   \n",
      "\n",
      "wavelength       699       700  \n",
      "agp         0.007647  0.007307  \n",
      "cgp         0.130930  0.130410  \n",
      "ap          0.007547  0.007307  \n",
      "ag          0.000100  0.000000  \n",
      "\n",
      "[4 rows x 11739 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ”¹ Load your CSV\n",
    "file_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- Clean and prepare ---\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols = [c for c in [\"wavelength\", \"agp\", \"cgp\", \"ap\", \"ag\"] if c in df.columns]\n",
    "df = df[cols]\n",
    "\n",
    "# Drop NaNs and ensure numeric wavelength\n",
    "df = df.dropna(subset=[\"wavelength\"])\n",
    "df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"wavelength\"])\n",
    "\n",
    "# --- Transpose ---\n",
    "# Set wavelength as columns, parameter names as rows\n",
    "df_t = df.set_index(\"wavelength\").T\n",
    "\n",
    "# Optional: make wavelength column headers integers\n",
    "df_t.columns = df_t.columns.astype(int)\n",
    "\n",
    "# --- Save the transposed version ---\n",
    "output_path = \"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_transposed.csv\"\n",
    "df_t.to_csv(output_path)\n",
    "\n",
    "print(f\"âœ… Transposed wavelengths saved to:\\n{output_path}\")\n",
    "print(f\"Shape: {df_t.shape}\")\n",
    "print(df_t.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb46bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transposed file saved at:\n",
      "/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/wavelength_transposed_with_filename_cruise.csv\n",
      "\n",
      "ğŸ” Preview of transposed table:\n",
      "\n",
      "wavelength          cruise      filename parameter       400       401  \\\n",
      "0           unknown_cruise  unknown_file       agp  0.077334  0.077756   \n",
      "1           unknown_cruise  unknown_file       cgp  0.219700  0.218710   \n",
      "2           unknown_cruise  unknown_file        ap  0.008705  0.009381   \n",
      "3           unknown_cruise  unknown_file        ag  0.069318  0.068140   \n",
      "\n",
      "wavelength       402       403       404       405       406  ...       691  \\\n",
      "0           0.078085  0.077690  0.078085  0.078085  0.077690  ...  0.010166   \n",
      "1           0.217730  0.216390  0.215540  0.214750  0.214200  ...  0.133130   \n",
      "2           0.010058  0.011752  0.012013  0.012232  0.014352  ...  0.009278   \n",
      "3           0.066961  0.066425  0.065853  0.065677  0.064252  ...  0.000887   \n",
      "\n",
      "wavelength       692       693       694       695       696       697  \\\n",
      "0           0.009759  0.009488  0.009174  0.008859  0.008533  0.008230   \n",
      "1           0.132740  0.132450  0.132160  0.131810  0.131640  0.131460   \n",
      "2           0.008959  0.008758  0.008502  0.008320  0.008116  0.007903   \n",
      "3           0.000800  0.000730  0.000672  0.000539  0.000417  0.000327   \n",
      "\n",
      "wavelength       698       699       700  \n",
      "0           0.007899  0.007647  0.007307  \n",
      "1           0.131230  0.130930  0.130410  \n",
      "2           0.007741  0.007547  0.007307  \n",
      "3           0.000158  0.000100  0.000000  \n",
      "\n",
      "[4 rows x 9033 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ Input and output paths\n",
    "input_path = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\")\n",
    "output_path = input_path.parent / \"wavelength_transposed_with_filename_cruise.csv\"\n",
    "\n",
    "# --- Load and clean ---\n",
    "df = pd.read_csv(input_path)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# --- Basic checks ---\n",
    "if \"wavelength\" not in df.columns:\n",
    "    raise ValueError(\"âŒ No 'wavelength' column found in the dataset.\")\n",
    "\n",
    "param_cols = [c for c in [\"agp\", \"cgp\", \"ap\", \"ag\"] if c in df.columns]\n",
    "if not param_cols:\n",
    "    raise ValueError(\"âŒ No optical parameter columns found (agp, cgp, ap, ag).\")\n",
    "\n",
    "# --- Handle wavelength values ---\n",
    "df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"wavelength\"])\n",
    "\n",
    "# --- Add filename and cruise columns if missing ---\n",
    "if \"filename\" not in df.columns:\n",
    "    df[\"filename\"] = \"unknown_file\"\n",
    "\n",
    "if \"cruise\" not in df.columns:\n",
    "    # Try to infer cruise name from filename pattern, e.g. \"CAH1609_xxx\"\n",
    "    df[\"cruise\"] = df[\"filename\"].str.extract(r\"([A-Z]{3}\\d{4})\", expand=False)\n",
    "    df[\"cruise\"] = df[\"cruise\"].fillna(\"unknown_cruise\")\n",
    "\n",
    "# --- Group by filename (and cruise) and transpose ---\n",
    "output_list = []\n",
    "\n",
    "for (fname, cruise), group in df.groupby([\"filename\", \"cruise\"]):\n",
    "    # Keep wavelength + parameter columns\n",
    "    sub = group[[\"wavelength\"] + param_cols].dropna()\n",
    "    sub = sub.set_index(\"wavelength\").T  # Transpose wavelengths -> columns\n",
    "    sub.columns = sub.columns.astype(int)  # Make wavelength integer columns\n",
    "\n",
    "    # Add identifying info\n",
    "    sub.insert(0, \"parameter\", sub.index)\n",
    "    sub.insert(0, \"filename\", fname)\n",
    "    sub.insert(0, \"cruise\", cruise)\n",
    "\n",
    "    output_list.append(sub.reset_index(drop=True))\n",
    "\n",
    "# --- Combine all and save ---\n",
    "final_df = pd.concat(output_list, ignore_index=True)\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Transposed file saved at:\\n{output_path}\")\n",
    "print(\"\\nğŸ” Preview of transposed table:\\n\")\n",
    "print(final_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57781b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31009_acs_R2.csv\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31015_acs_R2.csv\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31022_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31033_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31004_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31018_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31001_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31036_acs_R2\n",
      "âš ï¸ File not found: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/CAH1609_31027_acs_R2\n",
      "âŒ No valid data blocks found to transpose.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ Define the folder path\n",
    "data_folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\")\n",
    "\n",
    "# ğŸ”¹ List of specific files to process\n",
    "files_to_process = [\"CAH1609_31009_acs_R2.csv\", \"CAH1609_31015_acs_R2.csv\", \"CAH1609_31022_acs_R2\", \"CAH1609_31033_acs_R2\", \"CAH1609_31004_acs_R2\", \"CAH1609_31018_acs_R2\",\"CAH1609_31001_acs_R2\",\"CAH1609_31036_acs_R2\",\"CAH1609_31027_acs_R2\"]\n",
    "\n",
    "# ğŸ”¹ Output path\n",
    "output_path = data_folder / \"CAH1609_transposed.csv\"\n",
    "\n",
    "# ğŸ”¹ Initialize list for all file results\n",
    "transposed_blocks = []\n",
    "\n",
    "for fname in files_to_process:\n",
    "    fpath = data_folder / fname\n",
    "\n",
    "    if not fpath.exists():\n",
    "        print(f\"âš ï¸ File not found: {fpath}\")\n",
    "        continue\n",
    "\n",
    "    # --- Load CSV ---\n",
    "    df = pd.read_csv(fpath)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # --- Keep only needed columns ---\n",
    "    keep_cols = [col for col in [\"wavelength\", \"cgp\", \"agp\", \"ap\", \"ag\"] if col in df.columns]\n",
    "    if len(keep_cols) < 2:\n",
    "        print(f\"âš ï¸ Skipping {fname} â€” missing optical columns.\")\n",
    "        continue\n",
    "\n",
    "    df = df[keep_cols].dropna(subset=[\"wavelength\"])\n",
    "    df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"wavelength\"]).sort_values(\"wavelength\")\n",
    "\n",
    "    # --- Transpose wavelengths as columns ---\n",
    "    df_t = df.set_index(\"wavelength\").T\n",
    "    df_t.columns = df_t.columns.astype(int)  # wavelength â†’ int\n",
    "\n",
    "    # --- Add metadata columns ---\n",
    "    cruise = fname.split(\"_\")[0]  # Extract cruise name like \"CAH1609\"\n",
    "    df_t.insert(0, \"parameter\", df_t.index)\n",
    "    df_t.insert(0, \"filename\", fname)\n",
    "    df_t.insert(0, \"cruise\", cruise)\n",
    "\n",
    "    transposed_blocks.append(df_t.reset_index(drop=True))\n",
    "\n",
    "# --- Combine all results ---\n",
    "if transposed_blocks:\n",
    "    final_df = pd.concat(transposed_blocks, ignore_index=True)\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Transposed dataset saved to:\\n{output_path}\")\n",
    "    print(\"\\nğŸ” Preview:\")\n",
    "    print(final_df.head(10))\n",
    "else:\n",
    "    print(\"âŒ No valid data blocks found to transpose.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec51fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No '_acs_R2' CSV files found in /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609\n",
      "âŒ No valid data blocks found to transpose.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ Define your main path (file or folder)\n",
    "data_path = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\")\n",
    "\n",
    "# --- Detect if the path is a file or a folder ---\n",
    "if data_path.is_file():\n",
    "    data_folder = data_path.parent\n",
    "else:\n",
    "    data_folder = data_path\n",
    "\n",
    "# ğŸ”¹ Automatically find all *_acs_R2* files in this folder\n",
    "files_to_process = list(data_folder.glob(\"*_acs_R2*.csv\"))\n",
    "\n",
    "# If no CSVs found, letâ€™s log it\n",
    "if not files_to_process:\n",
    "    print(f\"âš ï¸ No '_acs_R2' CSV files found in {data_folder}\")\n",
    "else:\n",
    "    print(f\"ğŸ”¹ Found {len(files_to_process)} files to process.\")\n",
    "\n",
    "# ğŸ”¹ Output path\n",
    "output_path = data_folder / \"CAH1609_transposed.csv\"\n",
    "\n",
    "# ğŸ”¹ Initialize list for all file results\n",
    "transposed_blocks = []\n",
    "\n",
    "for fpath in files_to_process:\n",
    "    fname = fpath.name\n",
    "    print(f\"Processing â†’ {fname}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(fpath)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not read {fname}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- Keep only needed columns ---\n",
    "    keep_cols = [col for col in [\"wavelength\", \"cgp\", \"agp\", \"ap\", \"ag\"] if col in df.columns]\n",
    "    if len(keep_cols) < 2:\n",
    "        print(f\"âš ï¸ Skipping {fname} â€” missing optical columns.\")\n",
    "        continue\n",
    "\n",
    "    df = df[keep_cols].dropna(subset=[\"wavelength\"])\n",
    "    df[\"wavelength\"] = pd.to_numeric(df[\"wavelength\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"wavelength\"]).sort_values(\"wavelength\")\n",
    "\n",
    "    # --- Transpose wavelengths as columns ---\n",
    "    df_t = df.set_index(\"wavelength\").T\n",
    "    df_t.columns = df_t.columns.astype(int)\n",
    "\n",
    "    # --- Add metadata columns ---\n",
    "    cruise = fname.split(\"_\")[0]  # Extract cruise name like \"CAH1609\"\n",
    "    df_t.insert(0, \"parameter\", df_t.index)\n",
    "    df_t.insert(0, \"filename\", fname)\n",
    "    df_t.insert(0, \"cruise\", cruise)\n",
    "\n",
    "    transposed_blocks.append(df_t.reset_index(drop=True))\n",
    "\n",
    "# --- Combine and export ---\n",
    "if transposed_blocks:\n",
    "    final_df = pd.concat(transposed_blocks, ignore_index=True)\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Transposed dataset saved to:\\n{output_path}\")\n",
    "    print(\"\\nğŸ” Preview:\")\n",
    "    print(final_df.head(10))\n",
    "else:\n",
    "    print(\"âŒ No valid data blocks found to transpose.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16de7928",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/transposed_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotADirectoryError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ğŸ”¹ 3. Create output folder for transposed results\u001b[39;00m\n\u001b[32m     11\u001b[39m output_folder = base_folder / \u001b[33m\"\u001b[39m\u001b[33mtransposed_results\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43moutput_folder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ğŸ”¹ 4. Process each file\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m acs_r2_files:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/NewEnvironment/lib/python3.13/pathlib/_local.py:722\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m    720\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m    724\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[31mNotADirectoryError\u001b[39m: [Errno 20] Not a directory: '/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv/transposed_results'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# âœ… FIX: Point to the folder, not a file\n",
    "base_folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/combined_acs.csv\")\n",
    "\n",
    "# ğŸ”¹ 2. Find all \"_acs_R2.csv\" files recursively\n",
    "acs_r2_files = [f for f in base_folder.rglob(\"*_acs_R2.csv\")]\n",
    "\n",
    "# ğŸ”¹ 3. Create output folder for transposed results\n",
    "output_folder = base_folder / \"transposed_results\"\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# ğŸ”¹ 4. Process each file\n",
    "for file in acs_r2_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]  # normalize column names\n",
    "    \n",
    "    required_cols = {'wavelength', 'agp', 'cgp', 'ag', 'ap'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        print(f\"âš ï¸ Skipping {file.name}: missing one of {required_cols}\")\n",
    "        continue\n",
    "    \n",
    "    # ğŸ”¹ 5. Transpose so wavelength values become columns\n",
    "    df_t = df.set_index('wavelength')[['agp', 'cgp', 'ag', 'ap']].T\n",
    "    \n",
    "    # ğŸ”¹ 6. Add the filename (without extension) as an identifying column\n",
    "    df_t.insert(0, 'source_file', file.stem)\n",
    "    \n",
    "    # ğŸ”¹ 7. Save transposed file (non-destructive)\n",
    "    output_path = output_folder / f\"{file.stem}_transposed.csv\"\n",
    "    df_t.to_csv(output_path, index=True)\n",
    "    \n",
    "    print(f\"âœ… Transposed and saved: {output_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04b07286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Master CSV created: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/ACS_R2_Transposed_Master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ 1. Folder containing your ACS CSVs\n",
    "folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/\")\n",
    "\n",
    "# ğŸ”¹ 2. Find all \"_acs_R2.csv\" files\n",
    "acs_r2_files = list(folder.rglob(\"*_acs_R2.csv\"))\n",
    "\n",
    "# ğŸ”¹ 3. List to collect transposed DataFrames\n",
    "all_transposed = []\n",
    "\n",
    "# ğŸ”¹ 4. Process each file\n",
    "for file in acs_r2_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]  # normalize column names\n",
    "\n",
    "    required_cols = {'wavelength', 'agp', 'cgp', 'ag', 'ap'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        print(f\"âš ï¸ Skipping {file.name}: missing one of {required_cols}\")\n",
    "        continue\n",
    "\n",
    "    # ğŸ”¹ Sort by wavelength numerically\n",
    "    df = df.sort_values(by='wavelength')\n",
    "\n",
    "    # ğŸ”¹ Select only desired columns\n",
    "    df_selected = df[['wavelength', 'cgp', 'agp', 'ag', 'ap']]\n",
    "\n",
    "    # ğŸ”¹ Transpose: wavelengths become columns, rows = cgp, agp, ag, ap\n",
    "    df_t = df_selected.set_index('wavelength').T\n",
    "\n",
    "    # ğŸ”¹ Add source file name for identification\n",
    "    df_t.insert(0, 'source_file', file.stem)\n",
    "\n",
    "    # ğŸ”¹ Collect for master CSV\n",
    "    all_transposed.append(df_t)\n",
    "\n",
    "# ğŸ”¹ 5. Merge all transposed DataFrames into one master DataFrame\n",
    "if all_transposed:\n",
    "    master_df = pd.concat(all_transposed, ignore_index=True)\n",
    "    master_csv_path = folder / \"ACS_R2_Transposed_Master.csv\"\n",
    "    master_df.to_csv(master_csv_path, index=False)\n",
    "    print(f\"âœ… Master CSV created: {master_csv_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No valid ACS R2 files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab0854c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Master CSV created: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/ACS_R2_Transposed_Master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ 1. Folder containing your ACS CSVs\n",
    "folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609\")\n",
    "\n",
    "# ğŸ”¹ 2. Find all \"_acs_R2.csv\" files\n",
    "acs_r2_files = list(folder.rglob(\"*_acs_R2.csv\"))\n",
    "\n",
    "# ğŸ”¹ 3. List to collect transposed DataFrames\n",
    "all_transposed = []\n",
    "\n",
    "# ğŸ”¹ 4. Process each file\n",
    "for file in acs_r2_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]  # normalize column names\n",
    "\n",
    "    required_cols = {'wavelength', 'agp', 'cgp', 'ag', 'ap'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        print(f\"âš ï¸ Skipping {file.name}: missing one of {required_cols}\")\n",
    "        continue\n",
    "\n",
    "    # ğŸ”¹ Sort by wavelength numerically\n",
    "    df = df.sort_values(by='wavelength')\n",
    "\n",
    "    # ğŸ”¹ Transpose the desired columns\n",
    "    df_values = df[['cgp', 'agp', 'ap', 'ag']].T\n",
    "    df_values.columns = df['wavelength']  # set wavelengths as column headers\n",
    "\n",
    "    # ğŸ”¹ Add source_file as first column\n",
    "    df_values.insert(0, 'source_file', file.stem)\n",
    "\n",
    "    # ğŸ”¹ Append to list\n",
    "    all_transposed.append(df_values)\n",
    "\n",
    "# ğŸ”¹ 5. Combine all transposed DataFrames\n",
    "if all_transposed:\n",
    "    master_df = pd.concat(all_transposed, ignore_index=True)\n",
    "    master_csv_path = folder / \"ACS_R2_Transposed_Master.csv\"\n",
    "    master_df.to_csv(master_csv_path, index=False)\n",
    "    print(f\"âœ… Master CSV created: {master_csv_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No valid ACS R2 files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "696aef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Master CSV created: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609/ACS_R2_Transposed_Master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ 1. Folder containing your ACS CSVs\n",
    "folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CAH1609\")\n",
    "\n",
    "# ğŸ”¹ 2. Find all \"_acs_R2.csv\" files\n",
    "acs_r2_files = list(folder.rglob(\"*_acs_R2.csv\"))\n",
    "\n",
    "# ğŸ”¹ 3. List to collect transposed DataFrames\n",
    "all_transposed = []\n",
    "\n",
    "# ğŸ”¹ 4. Process each file\n",
    "for file in acs_r2_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]  # normalize column names\n",
    "\n",
    "    required_cols = {'wavelength', 'agp', 'cgp', 'ag', 'ap'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        print(f\"âš ï¸ Skipping {file.name}: missing one of {required_cols}\")\n",
    "        continue\n",
    "\n",
    "    # ğŸ”¹ Sort by wavelength numerically\n",
    "    df = df.sort_values(by='wavelength')\n",
    "\n",
    "    # ğŸ”¹ Transpose the desired columns\n",
    "    df_values = df[['cgp', 'agp', 'ag', 'ap']].T\n",
    "    df_values.columns = df['wavelength']  # set wavelengths as column headers\n",
    "\n",
    "    # ğŸ”¹ Add source_file as first column\n",
    "    df_values.insert(0, 'source_file', file.stem)\n",
    "\n",
    "    # ğŸ”¹ Add parameter name as second column\n",
    "    df_values.insert(1, 'parameter', df_values.index)\n",
    "\n",
    "    # ğŸ”¹ Append to list\n",
    "    all_transposed.append(df_values)\n",
    "\n",
    "# ğŸ”¹ 5. Combine all transposed DataFrames\n",
    "if all_transposed:\n",
    "    master_df = pd.concat(all_transposed, ignore_index=True)\n",
    "    master_csv_path = folder / \"ACS_R2_Transposed_Master.csv\"\n",
    "    master_df.to_csv(master_csv_path, index=False)\n",
    "    print(f\"âœ… Master CSV created: {master_csv_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No valid ACS R2 files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6744c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Master CSV created successfully: /Users/tuba/Downloads/UCONN/Dierssen/CORAL/CPA1705/VSF_R2_BBP_Transposed_Master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”¹ 1. Folder containing your VSF CSVs\n",
    "folder = Path(\"/Users/tuba/Downloads/UCONN/Dierssen/CORAL/CPA1705\")\n",
    "\n",
    "# ğŸ”¹ 2. Find all \"_vsf_R2.csv\" files\n",
    "vsf_r2_files = list(folder.rglob(\"*_vsf_R2.csv\"))\n",
    "\n",
    "# ğŸ”¹ 3. List to collect transposed DataFrames\n",
    "all_transposed = []\n",
    "\n",
    "# ğŸ”¹ 4. Process each file\n",
    "for file in vsf_r2_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = [c.strip().lower() for c in df.columns]  # normalize column names\n",
    "\n",
    "        # ğŸ”¹ Identify possible sorting & wavelength columns\n",
    "        wavelength_col = 'wavelength' if 'wavelength' in df.columns else None\n",
    "        serial_col = 'serial' if 'serial' in df.columns else None\n",
    "\n",
    "        # ğŸ”¹ Required optical columns (bbp, bbp_bp)\n",
    "        value_cols = [col for col in ['bbp', 'bbp_bp'] if col in df.columns]\n",
    "        if not value_cols:\n",
    "            print(f\"âš ï¸ Skipping {file.name}: missing 'bbp' or 'bbp_bp' columns.\")\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¹ Sort by serial if available, otherwise by wavelength\n",
    "        if serial_col:\n",
    "            df = df.sort_values(by=serial_col)\n",
    "        elif wavelength_col:\n",
    "            df = df.sort_values(by=wavelength_col)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Skipping {file.name}: no serial or wavelength column found.\")\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¹ Use wavelength or serial for column headers\n",
    "        if wavelength_col:\n",
    "            col_headers = df[wavelength_col]\n",
    "        else:\n",
    "            col_headers = df[serial_col]\n",
    "\n",
    "        # ğŸ”¹ Transpose selected columns\n",
    "        df_values = df[value_cols].T\n",
    "        df_values.columns = col_headers  # wavelength/serial values as headers\n",
    "\n",
    "        # ğŸ”¹ Add identifying columns\n",
    "        df_values.insert(0, 'source_file', file.stem)\n",
    "        df_values.insert(1, 'parameter', df_values.index)\n",
    "\n",
    "        # ğŸ”¹ Append to list\n",
    "        all_transposed.append(df_values)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file.name}: {e}\")\n",
    "\n",
    "# ğŸ”¹ 5. Combine all transposed DataFrames into one master file\n",
    "if all_transposed:\n",
    "    master_df = pd.concat(all_transposed, ignore_index=True)\n",
    "    master_csv_path = folder / \"VSF_R2_BBP_Transposed_Master.csv\"\n",
    "    master_df.to_csv(master_csv_path, index=False)\n",
    "    print(f\"âœ… Master CSV created successfully: {master_csv_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No valid VSF R2 files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bcf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
